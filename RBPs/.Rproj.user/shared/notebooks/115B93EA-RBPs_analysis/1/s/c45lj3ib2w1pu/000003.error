{"frames":[{"character_number":0,"end_character_number":0,"end_line_number":0,"file":"","func":"plot_eql_diff_binomial_table(paste(\"./RBPs/exon.up_plus.bed.filtered.100bp_intron.intersect_wao.All_G4.tsv.clean_minus_strand.woG4.score.\", \n    sample, \".bed.list.out.num\", sep = \"\"), paste(\"./RBPs/exon.up_minus.bed.filtered.100bp_intron.intersect_wao.All_G4.tsv.clean_plus_strand.woG4.score.\", \n    sample, \".bed.list.out.num\", sep = \"\"), paste(\"./RBPs/exon.down_plus.bed.filtered.100bp_intron.intersect_wao.All_G4.tsv.clean_minus_strand.woG4.score.\", \n    sample, \".bed.list.out.num\", sep = \"\"), paste(\"./RBPs/exon.down_minus.bed.filtered.100bp_intron.intersect_wao.All_G4.tsv.clean_plus_strand.woG4.score.\",  ...","line_number":0},{"character_number":1,"end_character_number":45,"end_line_number":16,"file":"","func":"read_dist_table(eql_up_minus)","line_number":16},{"character_number":1,"end_character_number":20,"end_line_number":5,"file":"","func":"data.table(read_delim(path, \"\\t\", escape_double = FALSE, col_names = FALSE, \n    trim_ws = TRUE))","line_number":3},{"character_number":1,"end_character_number":20,"end_line_number":5,"file":"","func":"read_delim(path, \"\\t\", escape_double = FALSE, col_names = FALSE, \n    trim_ws = TRUE)","line_number":3},{"character_number":0,"end_character_number":0,"end_line_number":0,"file":"","func":"read_delimited(file, tokenizer, col_names = col_names, col_types = col_types, \n    locale = locale, skip = skip, skip_empty_rows = skip_empty_rows, \n    comment = comment, n_max = n_max, guess_max = guess_max, \n    progress = progress)","line_number":0},{"character_number":0,"end_character_number":0,"end_line_number":0,"file":"","func":"col_spec_standardise(data, skip = skip, skip_empty_rows = skip_empty_rows, \n    comment = comment, guess_max = guess_max, col_names = col_names, \n    col_types = col_types, tokenizer = tokenizer, locale = locale)","line_number":0},{"character_number":0,"end_character_number":0,"end_line_number":0,"file":"","func":"guess_types(ds, tokenizer, locale, guess_max = guess_max)","line_number":0},{"character_number":0,"end_character_number":0,"end_line_number":0,"file":"","func":"guess_types_(datasource, tokenizer, locale, n = guess_max)","line_number":0}],"message":"Error: vector memory exhausted (limit reached?)\n"}